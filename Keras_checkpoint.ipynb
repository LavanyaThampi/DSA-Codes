{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9CWEk-g2tC0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from os.path import join\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "J1r9RPIT226V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the data\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "id": "PbnyA0iB3BQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(28, 28, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "wuS3jKsC3Lw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"best_model.keras\"\n",
        "check_point = ModelCheckpoint(filepath= filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')"
      ],
      "metadata": {
        "id": "SehL0R6-3ZTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile te model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "RTJndkMe6L94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size = 32, validation_data=(x_test, y_test), callbacks=[check_point])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpW30Pvv5ysM",
        "outputId": "df20243f-7d8a-478c-d9cd-3acf79e3d0f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1870/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5486 - loss: 4.2838\n",
            "Epoch 1: val_accuracy improved from -inf to 0.80160, saving model to best_model.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5490 - loss: 4.2753 - val_accuracy: 0.8016 - val_loss: 0.7263\n",
            "Epoch 2/10\n",
            "\u001b[1m1873/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.5617\n",
            "Epoch 2: val_accuracy improved from 0.80160 to 0.89920, saving model to best_model.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8504 - loss: 0.5616 - val_accuracy: 0.8992 - val_loss: 0.4111\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.3169\n",
            "Epoch 3: val_accuracy improved from 0.89920 to 0.93180, saving model to best_model.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9133 - loss: 0.3169 - val_accuracy: 0.9318 - val_loss: 0.2743\n",
            "Epoch 4/10\n",
            "\u001b[1m1872/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.2165\n",
            "Epoch 4: val_accuracy improved from 0.93180 to 0.94540, saving model to best_model.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.2165 - val_accuracy: 0.9454 - val_loss: 0.2177\n",
            "Epoch 5/10\n",
            "\u001b[1m1863/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1689\n",
            "Epoch 5: val_accuracy improved from 0.94540 to 0.95270, saving model to best_model.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1690 - val_accuracy: 0.9527 - val_loss: 0.2001\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1490\n",
            "Epoch 6: val_accuracy did not improve from 0.95270\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9580 - loss: 0.1491 - val_accuracy: 0.9274 - val_loss: 0.2893\n",
            "Epoch 7/10\n",
            "\u001b[1m1869/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1367\n",
            "Epoch 7: val_accuracy improved from 0.95270 to 0.95710, saving model to best_model.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.1367 - val_accuracy: 0.9571 - val_loss: 0.1749\n",
            "Epoch 8/10\n",
            "\u001b[1m1864/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.1229\n",
            "Epoch 8: val_accuracy did not improve from 0.95710\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.1229 - val_accuracy: 0.9560 - val_loss: 0.1882\n",
            "Epoch 9/10\n",
            "\u001b[1m1869/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.1087\n",
            "Epoch 9: val_accuracy improved from 0.95710 to 0.96510, saving model to best_model.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.1087 - val_accuracy: 0.9651 - val_loss: 0.1592\n",
            "Epoch 10/10\n",
            "\u001b[1m1871/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.0990\n",
            "Epoch 10: val_accuracy did not improve from 0.96510\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.0990 - val_accuracy: 0.9614 - val_loss: 0.1634\n"
          ]
        }
      ]
    }
  ]
}